[
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Welcome! This website is dedicated to any reader who may find the content here useful.\n"
},
{
	"uri": "/programming/r/reshaping_data/",
	"title": "Reshaping_data",
	"tags": [],
	"description": "",
	"content": "Pivot Longer This involves reshaping data from wide to long format. This means that the length of new dataframe will increase vertically as more rows gets added to the dataframe.\nSyntax:\npivot_longer(data, cols, names_to =\u0026#34;name\u0026#34;, values_to = \u0026#34;values\u0026#34;) Pivot Wider This involves reshaping data from long to wide format. This means horizontal expansion by adding new columns.\nReshaping is most easily accomplished using the tidyr package in R. Below are the cheetsheets from tidyr page.\n"
},
{
	"uri": "/acad/",
	"title": "Acads",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/acad/fellowships/",
	"title": "Fellowships",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/acad/fellowships/fellowship_list/",
	"title": "Fellowship_list",
	"tags": [],
	"description": "",
	"content": "The following is a list of fellowships targeted towards grad students in economics.\nhttps://sites.google.com/view/elisagiannone/others?authuser=0\n"
},
{
	"uri": "/programming/r/grouping_in_r/",
	"title": "Grouping_in_R",
	"tags": [],
	"description": "",
	"content": "Group would be perhaps one of the most frequently used tools in R. Grouping becomes handy with the dplyr library, so we\u0026rsquo;ll be using that.\nThe syntax is as follows:\ndf_grouped \u0026lt;- df %\u0026gt;% group_by(col_names) %\u0026gt;% summarize(gr_col_name = function(col_name)) # Given below are a list of functions that be used: sum min max mean sd IQR mad quantile(col_name, probs = .9) #- finds the 90th percentile for group n() #-counts the number of observations n_distinct(col_name) #- counts the number of unique observations Example:\nclass_mean \u0026lt;- scores %\u0026gt;% group_by(class_code) %\u0026gt;% summarize(mean_score = mean(marks)) Custom functions with mutate Instead of using predefined functions as done in the previous case, we can also apply custom functions using the mutate command.\nNote: Mutate retains all the rows of the original dataset unlike summarize which keeps only the columns passed into it.\nExample:\ndf %\u0026gt;% mutate(mean_bpm = (bpm - mean(bpm))^2) Group and select df %\u0026gt;% mutate(mean_bpm = (bpm - mean(bpm))^2) %\u0026gt;% select(genre, mean_bpm) Ungroup Example:\ndf %\u0026gt;% group_by(genre) %\u0026gt;% mutate(mean_bpm = mean(bpm) %\u0026gt;% mutate(my_grouped_sum = sum(mean_bpm)) %\u0026gt;% ungroup() %\u0026gt;% mutate(my_regular_sum = sum(mean_bpm)) Reference https://builtin.com/data-science/grouping-r\nhttps://www.statology.org/group-summarize-data-r/\n"
},
{
	"uri": "/datasets/wrds/",
	"title": "WRDS",
	"tags": [],
	"description": "",
	"content": "WRDS is the go to database to access all finance related datasets. Navigating through WRDS can be challenging for beginners.\nThe first order of business should be to register for WRDS at https://wrds-www.wharton.upenn.edu/ using your university email. Universities usually subscribe to part of the database.\nNext read the guide here: https://libguides.stanford.edu/library/wrds to have an intially idea of which dataset to look for.\nCompustat Compustat contains financial data for all publicly traded firms in US. The data is organizes is separate files. The list of files can be found here: https://wrds-www.wharton.upenn.edu/data-dictionary/comp_na_daily_all/\nUsually researchers use the funda file for Annual Company level fundamental variables. The names file contains information on year for which compustat data is available for a company.\nThe data dictionary for compustat variables can also be accesses here: https://wrds-www.wharton.upenn.edu/documents/1583/Compustat_Data_Guide.pdf\nWRDS SSH Access All the files listed in the data files listed in the data dictionary can be accessed via ssh server.\nTo login type the following in terminal:\nssh ursername@wrds-cloud.wharton.upenn.edu The daily North America (d_na) files are located at:\n/wrdslin/comp/sasdata/d_na/ "
},
{
	"uri": "/datasets/data_at_umn/",
	"title": "Data_at_umn",
	"tags": [],
	"description": "",
	"content": "University of Minnesota Library also provides access to several datasets. For instance it subscribes to Statista. For a more comprehensive list visit the link below:\nhttps://libguides.umn.edu/FindResourcesbyFormat/datasets\nThere is also a specific section related to economics here:\nhttps://libguides.umn.edu/econdata\nIn addition, if one needs access to restricted-use datasets, one can contact the FSRDC at Minnesota. Here is their webpage:\nhttps://mnrdc.umn.edu/\nOne will typically need a research proposal to gain access to restricted-datasets.\nThe government recently launched a website to smoothen the process of getting access to restricted data. Visit the following website:\nhttps://www.researchdatagov.org/\nOne can read the eligibility requirement here: https://manager.researchdatagov.org/RDG_User_Guide.pdf\n"
},
{
	"uri": "/datasets/patents_and_innovation/",
	"title": "Patents_and_innovation",
	"tags": [],
	"description": "",
	"content": "https://iiindex.org/datasets\nhttps://docs.google.com/spreadsheets/d/1bdyhGrj0oNz-_qW3Rv2GNGqhZZ73rgj-DYWePLA_1Ms/edit#gid=1389884911\n"
},
{
	"uri": "/datasets/data_aggregators/",
	"title": "Data_aggregators",
	"tags": [],
	"description": "",
	"content": "Below is a website that does exactly what I\u0026rsquo;m trying to do - list all the datasets that can be useful for research.\nhttps://econdata.net/subject-links/ Several of the links in the above website are broken, but still serves as a good guide.\nHere I list website which aggregate and clean data from different places.\n1. IPUMS https://www.ipums.org/\n2. NHGIS https://www.nhgis.org/\n3. Social Explorer https://www.socialexplorer.com/explore-maps\n"
},
{
	"uri": "/datasets/lbd/",
	"title": "LBD",
	"tags": [],
	"description": "",
	"content": "The Longitudinal Business Database (LBD) is restricted use micro data on firms.\nhttps://www.census.gov/programs-surveys/ces/data/restricted-use-data/longitudinal-business-database.html\n"
},
{
	"uri": "/datasets/",
	"title": "Datasets",
	"tags": [],
	"description": "",
	"content": "This directory contains information on datasets that can be useful for your research.\n"
},
{
	"uri": "/programming/r/recursively_reduce/",
	"title": "Recursively_reduce",
	"tags": [],
	"description": "",
	"content": "Reduce is a powerful function in R. It applies a function recursively to a list. One simple use of reduce function is to merge large number of datasets in a recursive fashion.\nReduce usually takes a binary function and a list as its input.\nExample:\nReduce(intersect, list(a, b, c)) # This is same as the command below intersect((intersect(a,b),c) "
},
{
	"uri": "/programming/r/merging_in_r/",
	"title": "Merging_in_R",
	"tags": [],
	"description": "",
	"content": "Merging in R The first thing to note is that there are four standard SQL joins: Inner, Outer, Right, and Left.\nInner Join: This means the merged dataset will have the common elements of the two datasets by the column name declared.\nmerge(df1, df2, by=\u0026#34;col_name\u0026#34;) #this will merge based on common columns in the two datasets # this is a inner join which keeps only the common elements in the two datasets Make sure that one has unique values in the declared column by which merging is to be done. In case the values in the columns in which merging is to be carried out is not unique, the result will be a cross product of rows.\nOuter Join: This joins datasets with elements present in any one of them.\nmerge(df1, df2, all = TRUE) Left Join: Merging based on all values present in the left dataset\nmerge(df1, df2, all.x = TRUE) This is like the 1:m merge in stata, hence make sure that the values in x are unique.\nRight Join: Merging based on all values present in the right dataset\nmerge(df1, df2, all.y = TRUE) This is like the m:1 merge in stata, hence make sure that the values in y are unique.\nReference https://r-coder.com/merge-r/\n"
},
{
	"uri": "/programming/stata/loops/",
	"title": "Loops",
	"tags": [],
	"description": "",
	"content": "For loop in stata Looping through parallel lists local agrp \u0026#34;cat dog cow pig\u0026#34; local bgrp \u0026#34;meow woof moo oinkoink\u0026#34; local n : word count `agrp\u0026#39; forvalues i = 1/`n\u0026#39; { local a : word `i\u0026#39; of `agrp\u0026#39; local b : word `i\u0026#39; of `bgrp\u0026#39; di \u0026#34;`a\u0026#39; says `b\u0026#39;\u0026#34; } /// Output cat says meow dog says woof cow says moo pig says oinkoink References https://www.stata.com/support/faqs/programming/looping-over-parallel-lists/ "
},
{
	"uri": "/programming/r/apply_fns/",
	"title": "Apply_fns",
	"tags": [],
	"description": "",
	"content": "There are different kinds of apply functions:\napply lapply sapply mapply vapply rapply tappy The reason that there are so many kinds of apply function in R is that we want to avoid making use of for loop as much as possible. The class of apply functions are more optimized that loops.\napply apply(df, 1, fun) # Row-wise operation apply(df, 2, fun) # Column-wise operation Reference https://www.datasciencemadesimple.com/apply-function-r/\n"
},
{
	"uri": "/programming/terminal/",
	"title": "Terminal",
	"tags": [],
	"description": "",
	"content": "Some useful terminal commands mkdir dir_name # Make Directory rm -r dir_name # Recursively remove content of a directory mv file1 dir1/ # move file1 to dir1 wget -O dir/file.ext url # download the file from url and save it in dir with filename file.ext wget url -P dir # download the file from url as save it in dir unzip file.zip #to unzip a file touch file_name.ext # create a new file open -a app_name file_name # open file using a specific application Accessing terminal command history Press Ctrl + R to enter the command history mode. Type the command for which you are looking the history for. To keep scrolling through the history press Ctrl + R "
},
{
	"uri": "/programming/r/string_man/",
	"title": "String_man",
	"tags": [],
	"description": "",
	"content": "String Manipulation in R Paste Function The paste function in R is used to join strings together.\n\u0026gt;paste0(\u0026#34;a\u0026#34;, 1:3) \u0026gt; \u0026#34;a1\u0026#34; \u0026#34;a2\u0026#34; \u0026#34;a3\u0026#34; \u0026gt;paste(\u0026#34;a\u0026#34;, 1:3) \u0026gt; \u0026#34;a 1\u0026#34; \u0026#34;a 2\u0026#34; \u0026#34;a 3\u0026#34; Sprintf Function The sprintf function prints strings in a specified format. Examples:\nsprintf(\u0026#34;%06d\u0026#34;, 12) # \u0026#34;000012\u0026#34; - 6 digits with leading zeros sprintf(\u0026#34;%.2f\u0026#34;, 15.45678) # \u0026#34;15.49\u0026#34; - prints upto two decimal places "
},
{
	"uri": "/programming/r/r_plots/",
	"title": "R_plots",
	"tags": [],
	"description": "",
	"content": "R Plots We\u0026rsquo;ll start by describing the functioning of the inbuilt R plot function, though there are better packages like ggplot.\nplot(x_axis_data, y_axis_data, type=\u0026#34;l\u0026#34;, col=\u0026#34;b\u0026#34;, xlab=\u0026#34;label_x\u0026#34;, ylab=\u0026#34;label_y\u0026#34;, xlim=c(0, 10), ylim=c(-10, 20)) title(main=\u0026#34;TITLE\u0026#34;, sub=\u0026#34;subtile\u0026#34;) GG Plots "
},
{
	"uri": "/random/",
	"title": "Randoms",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/random/us_geo_division/",
	"title": "US Geographical Division by Authority",
	"tags": [],
	"description": "",
	"content": "Different US authorities divides US into different regions. Here is a list of number of regions that the entire US is divided into by name of authority.\nTable: Total number of divisions by authority1\nAuthority Number of regions Region Names US Census Bureau 4 NE; MW; S; W Federal Reserve System 12 see here Time Zones 4 (+2) Eastern; Central; Mountain; Pacific (+Alaska; Hawaii) Federal Court System 13 see here BEA Regions 8 New Eng; ME; SE; Great Lakes; Plains; SW; Rocky Mountains; Far W Petroleum Administration of Defence Districts (PADD) 5 E Coast; W Coast; Gulf Coast; MW; Rocky Mountains Reference: https://www.businessinsider.in/undefined/slidelist/undefined.cms#slideid=64111585\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
},
{
	"uri": "/programming/vim/",
	"title": "Vim",
	"tags": [],
	"description": "",
	"content": "CAUTION It is strictly advised not to use vim if one is not a pro programmer. One is most likely to waste a lot of time doing simple stuffs on vim. This guide is meant as a basic starting point to browse through files, make some small changes using terminal and vim. For programming the best IDE in my opinion is VS Code.\nBasic Editing with Vim Vim is a powerful text editor designed in such a manner such that one has to never leave the keyboard. So here are some basics.\nThere are three basic modes: (i) the command mode, (ii) the insert or edit mode, (iii) last line mode. The command mode is basically to browse through the files. This is the mode the file will open as default. In this mode one can\u0026rsquo;t edit the file. To edit the mode one has to go to the insert mode by pressing the `i\u0026rsquo; key. The last line mode is where we enter the commands to save files or perform other functionalities.\nBasic Navigation h, j, k, l are used to navigate the pointer left, down, up and right. w, b are used to move between words 0, $ to move between beginning, and end of line gg, G to move to beginning, and end of file ZZ to save and exit. e to move cursor to the end of line 20G to jumps to line 20 in vim Scrolling in Vim ctrl+d: scroll down ctrl+u: scroll up ctrl+f: one page forward ctrl+b: one page backward\nInsert Mode positioning There are several keys to jump to insert mode. The following is a list of keys with their functionality. Note: By default everything is typed to the left of cursor. i - will begin the insert mode at the current position of the cursor a - will begin the insert mode by placing cursor to one character to the right I - append at the beginning of a line A - append at the end of a line\nDelete Functionalities: d starts the delete operation. Once we have entered this operation the navigation h,j,k, l will still be operational. d followed by the standard line jumping keys will implement delete for those commands. For instance: d0, d$, dgg, dG, deletes to the beginning, end x delete character Note: The detele functionality is the same as cutting the text. It is temperorily stored in the buffer.\nCopy and pasting The basic idea here is to enter the selection mode using v or V. Once we are in the selection mode, we can use the usual navigation tools to select the desired texts. V will select by line, v by words. The letter \u0026lsquo;y\u0026rsquo; which stands for yank copies the selected text to the buffer. To paste the selcted text, just use \u0026lsquo;p\u0026rsquo;. To cut and paste in the visual mode one can use \u0026rsquo;d\u0026rsquo; followed by \u0026lsquo;p\u0026rsquo;.\nWorking on Multiple files using Vim Some other useful commands To push vim to the background and return to the terminal we do \u0026lsquo;ctrl+z\u0026rsquo;. To come back we just type \u0026lsquo;fg\u0026rsquo;. To display line number we use \u0026lsquo;:set number\u0026rsquo; or \u0026lsquo;:set nu\u0026rsquo; in short. Split Screen functionality In order to open multiple files in split screen at the same time use the command vi -o file1 file2\u0026rsquo;. By default it will open files in a horizontal split. To toggle between the horizontal screens we use the \u0026lsquo;ctrl + w\u0026rsquo; followed by j to move down and k to move up to move down and k to move up. The up and down keys works as well. Similarly \u0026lsquo;ctrl+ w\u0026rsquo; followed by h, l moves to left and right or one can simply use the cursor keys as well. To adujst the size of the splits: \u0026lsquo;ctrl+W\u0026rsquo; + = : equal horizonatal splits. Plugin Manager in Vim www.linuxhandbook.com/install-vim-plugins/\nVim Configurations Vim configrations are saved in the ~/.vimrc configration file.\nOne can add the follwing functionalites which will be active from the start.\nset number - this displays the line numbers Spell check in Vim Simply add set spell in the config file. [s or ]s are used to navigate between the misspelled words. z= will give a list of suggested words. References:\nhttps://www.linuxfoundation.org/blog/blog/classic-sysadmin-vim-101-a-beginners-guide-to-vim https://linuxhint.com/vim_split_screen/ \u0026ndash; this is regarding split functionalities. "
},
{
	"uri": "/datasets/cps/",
	"title": "CPS",
	"tags": [],
	"description": "",
	"content": "The Current Population Survey (CPS)\nThe Annual Social and Economic Supplement (ASEC) to the CPS contains data regarding labor market.\n"
},
{
	"uri": "/datasets/comets/",
	"title": "Comets",
	"tags": [],
	"description": "",
	"content": "The Connecting Outcome Measures in Entrepreneurship, Technology, and Science (COMETS) database primarily contains patents data and linking it to several other variables.\nData Source https://www.kauffman.org/entrepreneurship/research/comets/ "
},
{
	"uri": "/datasets/acs/",
	"title": "American Community Survey",
	"tags": [],
	"description": "",
	"content": "Type: Public Use MicroData\nThe American Community Survey (ACS) data on at household and individual level on variables related to demographics and income.\n"
},
{
	"uri": "/random/quotes/",
	"title": "Quotes",
	"tags": [],
	"description": "",
	"content": "“The size of your dreams must always exceed your current capacity to achieve them. If your dreams do not scare you, they are not big enough.” ― Ellen Johnson Sirleaf\nPoor people need more money, not self-help tricks.\nThe smallest deed is better than the greatest intention.\nQuotes by Albert Einstein It’s not that I’m so smart, it’s just that I stay with problems longer.\nThe only thing more dangerous than ignorance is arrogance.\nTry not to become a man of success but rather a man of value.\nThe search for truth is more important than its possession.\nQuotes by Strangers A good theory is hard to escape.\nAs long as there are minds to reason there will be a never ending sequence of questions- what is it that is true? why is something true? why is something not true? is something universally true? why?\nEnjoy the postponement of enjoyment to the constantly postponed future.\nTotal people on earth \u0026raquo; Total books on earth.\nLook for the win-wins in life.\n"
},
{
	"uri": "/programming/r/r_basic_data_analysis/",
	"title": "Basic_data_analysis",
	"tags": [],
	"description": "",
	"content": "Loading Dataset dataset_name \u0026lt;- read_dta(\u0026#34;./family_data.dta\u0026#34;) # read stata dta requires library(haven) df\u0026lt;-read.csv(\u0026#34;path\u0026#34;, header = T, sep = \u0026#34;,\u0026#34;, skip = 0) # read csv, include 1st row as column names, skip 0 rows. Saving Dataset save(df, \u0026#34;path/file_name.Rda\u0026#34;) # to save in Rda format write_dta(df, \u0026#34;path/file_name.dta\u0026#34;) # to save in stata dta format, requires library(haven) Data Exploration names(data) # gives the list of column names present in the dataset colnames(data) head(data) # gives a few starting values of the all column in the dataset dim(data) # gives the dimension fo the dataset i.e rows and columns str(data) # give the structure of columns in the dataset Select Columns subset(df, df$colname = c(a, c)) # This will select columns a and c from the dataset subset(df, select = c(a, c)) # another way of writing the same thing subset(df, select = -c(a, c)) # this will select all columns except a and c df[c(\u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;)] # select a and c column. Note that we have to write column names as strings in this case unlike when using subset df %\u0026gt;% select(a, c) # select columns a and c # requires library(dplyr) df %\u0026gt;% select(!(a:c)) # select all columns from a to c # There are many more selection options available with dplyr library -- look for the manual Rename Columns rename(df, new_name1 = old_name1, nn2 = on2) # requires library(dplyr) Reorder Columns df %\u0026gt;% select(col1, col2, col3, col4) # requires library(dplyr) # the above selects data in the order of columns as shown above df %\u0026gt;% select(col1, col2, everything()) # this order col1, col2 and keeps all the columns same as before. Select Rows df[(is.na(df$col1) \u0026amp; df$col2 !=0) | df$col3 == 10, ] # select rows based on given conditions df[!(df$colname %in% c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;)), ] # select rows excluding the ones that have a or c in colname. Sort Datasets based on Columns df_new \u0026lt;- df[order(df$col1,df$col2), ] This will sort the dataset in ascending order based on col1 and col2. For inverse sorting we just need to use the negative sign.\nCounting in R length(unique(vec)) # count the number of unique values sum(is.na(vec)) # count the number of NAs Reference https://www.statology.org/reorder-columns-r/\n"
},
{
	"uri": "/programming/r/r_basics/",
	"title": "R_basics",
	"tags": [],
	"description": "",
	"content": "Intro To begin with we first set the working directory of a project. The code to do so is:\ngetwd() # This will give the current working directory setwd(\u0026#34;./../dir_path\u0026#34;) # This will set the new working directory. The next important thing is to learn to install and load packages. This can be done as seen in the following demostration.\ninstall.packages(\u0026#34;tidyverse\u0026#34;) # to install a package library(tidyverse) # to call a package Standard Packages in R tidyverse: This is a package specifically designed for data science. haven: This package allows R to read data from other statistical softwares like SAS, SPSS, Stata. Haven comes as a part of tidyverse stringr: used for string manipulations random: to draw random numbers Some Useful Commands remove(obj_name) # to remove object from workplace remove(list = ls()) # to remove everything from workplace source(\u0026#34;file_name.R\u0026#34;) # to run R script from start to end Some Useful Shortcuts cmd + shift + enter # to run the entire R script cmd + enter # to run current line cmd + shift + c # to comment out selected line "
},
{
	"uri": "/programming/git/git_basics/",
	"title": "Git_basics",
	"tags": [],
	"description": "",
	"content": "Basics of Version Control using Git Git is a platform for version control. If there are a large number of people working on a single project then keeping track of who made what changes when and where becomes very important.\nIn my experience the best way to learn git it by demostration.\nGetting a copy of repository on local device We don\u0026rsquo;t want to make changes in the original repository which is there in the cloud (or at remote-location), hence we make a clone (or copy) of the repository and save it locally. This is accomplished using git clone as demostrated below.\ngit clone \u0026lt;ssh or https url of repo\u0026gt; If nothing further is specified then a copy will be created in the current directory.\nCheck what changes have been made locally git status git add . git commit -m \u0026#34;comments\u0026#34; git push origin main "
},
{
	"uri": "/programming/stata/data_manupulation_stata/",
	"title": "Data_manupulation_stata",
	"tags": [],
	"description": "",
	"content": "Data Manipulation in Stata Any data manipulation essentially consists of Row Operations, Column Operations. Data in stata is usually stored in two dimensions - rows and columns. If there are more dimensions to the data then they will simply be stacked together. Data manipulation will most of the times involve construction of new columns based on existing columns.\nTIPS\nThe first thing to do is to identify at which level is the data unique. -Whenever generating new columns again remind at what level will the new column have unique data. Reduce the level of data at which the manipulation is req The collapse command The collapse command is used to reduce the micro level at which data is presented. For instance if the smallest level at which the data is presented is monthly level, then it can be collapsed to be presented at yearly level.\nThe following example is taken from stata tutorials ucla.\nSuppose we have a dataset that looks like the following:\nfamid sex sexdum1 sexdum2 1. 1 f 1 0 2. 1 m 0 1 3. 1 f 1 0 4. 2 m 0 1 5. 2 m 0 1 6. 2 f 1 0 7. 3 m 0 1 8. 3 f 1 0 9. 3 m 0 1 Then the collapse command as used below produces the following result.\ncollapse (count) numkids=famid (sum) girls=sexdum1 boys=sexdum2, by(famid) list famid boys girls numkids famid boys girls numkids 1. 1 1 2 3 2. 2 2 1 3 3. 3 2 1 3 Here the collapse function tells to count the total number of observation in the familyid variable and store it in numkids, sum the values in sexdum1 and store it in girls, sum values in sexdum2 and store it in boys \u0026mdash; all this will be done at the level of family as specified by the by command.\n"
},
{
	"uri": "/programming/stata/gen_vs_egen/",
	"title": "Gen_vs_egen",
	"tags": [],
	"description": "",
	"content": "I never understand the difference between the behaviour of gen and egen in stata. I this post I will try to collect resources that clarifies the difference between the two.\ngen vs egen sum The first thing to note is that gen is the simple guy which does what is asked for, however, egen likes to be a ninja - it does different things according to what function is it supplied with. egen literally stands for extended generate.\nset obs 10 gen a = _n // generates nos 1:10 egen b = sum(a) //gives the total sum gen b = sum(a) // give the running sum "
},
{
	"uri": "/programming/stata/stata_basics/",
	"title": "Stata Basics",
	"tags": [],
	"description": "",
	"content": "How to set the working directory in stata? The first thing to do when you start Stata is to set the working directory correctly.\nTo set the working directoty use the command:\ncd \u0026#34;\u0026lt;path to file\u0026gt;\u0026#34; cd \u0026#34;E:\\dataset\u0026#34; ///for example If the directory path name is long, then one can alternatively define a global variable and call it as and when required.\nglobal \u0026lt;var_name\u0026gt; \u0026#34;\u0026lt;directory_path_string\u0026gt;\u0026#34; global dataset \u0026#34;E:\\dataset\u0026#34; cd \u0026#34;$dataset\u0026#34; How to load dataset in stata? For this we use the following command.\nuse \u0026#34;\u0026lt;path_to_file\u0026gt;\u0026#34; use \u0026#34;E:\\dataset\\cars.dta\u0026#34; Basic data exploration in stata Once the dataset is laoded in temperory memory one can use the following commands.\ndescribe // gives the number of obervations and a list of variables codebook // gives summary statistics for each of the variable. The execution if this command may be slow if there are a lot of obervation or variables in the dataset. sum \u0026lt;variable_name\u0026gt; // gives the summary statistics for the selected variable list \u0026lt;var_name\u0026gt; // also give brief summary stats for the variables Another useful thing to identify about the dataset is what consititues a unique observation in the dataset.\nHelpful References There are a lot of resources out there to learn stata. Below are links to a few of them which themselves contain further links depending on the specifics.\nhttps://wlm.userweb.mwn.de/Stata/ https://www.stata.com/links/resources-for-learning-stata/ "
},
{
	"uri": "/programming/git/",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": "Welcome! This website is dedicted to any reader who may find the content here useful.\n"
},
{
	"uri": "/programming/",
	"title": "Programming",
	"tags": [],
	"description": "",
	"content": "Welcome! This website is dedicated to any reader who may find the content here useful.\n"
},
{
	"uri": "/programming/r/",
	"title": "R",
	"tags": [],
	"description": "",
	"content": "Welcome! This website is dedicted to any reader who may find the content here useful.\n"
},
{
	"uri": "/programming/stata/",
	"title": "Stata",
	"tags": [],
	"description": "",
	"content": "Welcome! This website is dedicted to any reader who may find the content here useful.\n"
},
{
	"uri": "/programming/creating_website/",
	"title": "Creating Website using Hugo and Github",
	"tags": [],
	"description": "",
	"content": "I was long looking for a hugo theme where I could organize my content in a tree directory structure. I finally found the one that I am currently using.\nThe theme is named the-roots-home. The link to its gihub repo is https://github.com/rmsubekti/the-roots-home\nIn order to learn how to actually publish contents, I used the tutorial here https://www.youtube.com/watch?v=LIFvgrRxdt4\nTo compile and view the site locally run\nhugo server Publishing Contents Once content has been added its time to public them on the internet.\nWebsite Organization I like the tree organization of the website. I have subdirectories created under the content/ directory to organize my contents. Note: In order to list all the directories, subdirectories, and posts exactly as in the content directory, it is necessary to have the _index.md file in each of the subdirectories. Reference: https://gohugo.io/content-management/sections/#nested-sections\nHappy Blogging!\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]